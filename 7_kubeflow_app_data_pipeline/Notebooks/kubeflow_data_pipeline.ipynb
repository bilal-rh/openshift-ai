{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443c2d2f-2b38-405f-82b2-f1a758a2aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp.compiler\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Input, Output, Artifact\n",
    "\n",
    "# Step 1: Download Image, Preprocess, Predict, and Decode Predictions\n",
    "@dsl.component(base_image=\"quay.io/nageshrathod/pipeline:pipeline1\")\n",
    "def download_and_predict(output_predictions: Output[Artifact]):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import requests\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "    model = MobileNetV2(weights='imagenet')\n",
    "    \n",
    "    # downloaad the image of cat to process it\n",
    "    url = \"https://raw.githubusercontent.com/redhat-developer-demos/openshift-ai/main/2_Cat-dog-prediction/cat.jpg\"\n",
    "    response = requests.get(url)\n",
    "    img_array = np.array(bytearray(response.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # create a numpy array for he model\n",
    "    data = np.empty((1, 224, 224, 3))\n",
    "    \n",
    "    # store our image inside tbhe batch of images\n",
    "    data[0] = img\n",
    "    data = preprocess_input(data)\n",
    "\n",
    "    #classify :\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    # how to get the predicitions :\n",
    "    np.save(output_predictions.path, predictions)\n",
    "\n",
    "# Step 2: Load Model and Save to .h5 Format\n",
    "@dsl.component(base_image=\"tensorflow/tensorflow:2.9.1\")\n",
    "def load_and_save_model(model_output: Output[Artifact]):\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "    import os\n",
    "\n",
    "    model_instance = MobileNetV2(weights='imagenet')\n",
    "    model_output_path = os.path.join(model_output.path, \"mobilenetv2_model.h5\")\n",
    "    model_instance.save(model_output_path)\n",
    "\n",
    "# Step 3: Convert MobileNetV2 Model to ONNX Format\n",
    "@dsl.component(base_image=\"quay.io/nageshrathod/pipeline:pipeline1\")\n",
    "def convert_model_to_onnx(model_input: Input[Artifact], onnx_model_output: Output[Artifact]):\n",
    "    import os\n",
    "    # import subprocess\n",
    "    import tf2onnx\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Load the TensorFlow model\n",
    "    model_instance = tf.keras.models.load_model(os.path.join(model_input.path, \"mobilenetv2_model.h5\"))\n",
    "\n",
    "    # Convert the model to ONNX format\n",
    "    onnx_model_content, _ = tf2onnx.convert.from_keras(model_instance, opset=13)\n",
    "\n",
    "    # Ensure the directory exists before saving the ONNX model    \n",
    "    onnx_model_path = os.path.join(onnx_model_output.path, \"mobilenetv2_model.onnx\")\n",
    "    os.makedirs(os.path.dirname(onnx_model_path), exist_ok=True)\n",
    "    \n",
    "    # Save the ONNX model\n",
    "    with open(onnx_model_path, \"wb\") as f:\n",
    "        f.write(onnx_model_content.SerializeToString())\n",
    "\n",
    "# # Step 4: Save ONNX Model to MinIO\n",
    "@dsl.component(base_image=\"quay.io/nageshrathod/pipeline:pipeline1\")\n",
    "def save_onnx_to_minio(onnx_model_input: Input[Artifact]):\n",
    "    import os\n",
    "    import boto3\n",
    "    from botocore.client import Config\n",
    "\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url='https://minio-api-nageshrathod-dev.apps.sandbox-abc.openshiftapps.com',\n",
    "        aws_access_key_id='minio',\n",
    "        aws_secret_access_key='minio123',\n",
    "        config=Config(signature_version='s3v4')\n",
    "    )\n",
    "    \n",
    "    bucket_name = 'mobilenet-v2'\n",
    "    object_name = 'models/mobilenetv2_model.onnx'\n",
    "\n",
    "    # Construct the full file path\n",
    "    onnx_model_file_path = os.path.join(onnx_model_input.path, \"mobilenetv2_model.onnx\")\n",
    "\n",
    "    # Upload the ONNX model file to MinIO\n",
    "    s3.upload_file(onnx_model_file_path, bucket_name, object_name)\n",
    "    \n",
    "    print(f\"ONNX model saved to MinIO bucket '{bucket_name}' with object name '{object_name}'.\")\n",
    "\n",
    "\n",
    "# Pipeline Definition\n",
    "@dsl.pipeline(name=\"image-prediction-pipeline\")\n",
    "def image_prediction_pipeline():\n",
    "    # Task 1: Download image, preprocess, and predict\n",
    "    download_and_predict_task = download_and_predict()\n",
    "\n",
    "    # Task 2: Load and save the model to .h5 format\n",
    "    save_model_task = load_and_save_model()\n",
    "    save_model_task.after(download_and_predict_task)\n",
    "\n",
    "    # Task 3: Convert the model to ONNX format\n",
    "    convert_to_onnx_task = convert_model_to_onnx(model_input=save_model_task.outputs['model_output'])\n",
    "    convert_to_onnx_task.after(save_model_task)\n",
    "\n",
    "    # Task 4: Save the ONNX model to MinIO\n",
    "    save_onnx_to_minio_task = save_onnx_to_minio(onnx_model_input=convert_to_onnx_task.outputs['onnx_model_output'])\n",
    "    save_onnx_to_minio_task.after(convert_to_onnx_task)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kfp.compiler.Compiler().compile(image_prediction_pipeline, package_path=\"image_prediction_data_pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925b96e3-7284-4cb3-9dc7-fbba54a762a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
